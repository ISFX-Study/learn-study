## 빅데이터분석기사 실기 3회차

---
### 1. 인공신경망
 - 개념: 뉴런의 전기신호 전달 과정을 모방한 기계학습 모델  
     https://blog.naver.com/samsjang/220948258166
	 https://4ir.kisti.re.kr/ick/cmmn/viewPost/20180226000067
 - 단층 퍼셉트론: 입력, 가중치, 순입력함수, 활성함수, 출력로 구성  
     ![image](https://images.velog.io/images/hyunsuki/post/548cf76e-f7c1-40a2-b64c-d3a244501f60/image.png)  
    순입력함수: 특성값에 가중치를 곱한 값을 모두 더하여 하나의 값으로 만드는 함수
	활성함수: 순입력함수의 결과값을 임계값과 비교한 결과를 출력하는 함수
 - 다층 퍼셉트론: 단층 퍼셉트론을 발전 시킨 것. 여러 은닉층과, 역전파 알고리즘을 이용함
     ![image](https://4ir.kisti.re.kr/file/download/20180226000511)  
    은닉층: 입력층에서 전달받은 특성값으로 연산하는 층(외부에서 직접 접근할 수 없음)  
	  역전파 알고리즘: 역방향으로 오차를 전파시키면서 각 층의 가중치를 업데이트하는 방식
  	 ![image](https://cdn.datamaker.io/datamaker-erp/media/uploads/2020/09/16/image-1_uzw2Se8.png)  
<br>

### 2. 딥러닝
 - 개념: 인공신경망 기반 기계학습 알고리즘
 - 용어: 딥러닝 = 심층신경망(DNN) = 다층 퍼셉트론
 - 활용: 딥러닝 적용한 CNN(합성곱), RNN(순환신경망), LSTM(장단기메모리)  
   , GAN(생성적 적대 신경망) 등 다양한 분석 모형
   1) Convolution Neural Network  
     - 이미지 처리에 특화됨, 특징을 추출하고 특징의 패턴을 파악함  
	  https://yjjo.tistory.com/8
	  ![image](https://miro.medium.com/v2/resize:fit:1040/1*3BRLw4lsANPEfGgimG3YVQ.png)  
   2) Recurrent Neural Network  
     - 시계열 데이터, 언어 데이터 등 순차적인 데이터 학습에 특화됨  
	   (기존 신경망은 과거의 학습을 현재 학습에 반영할 수 없음)  
	   과거의 학습 정보를 다음 학습에 사용하는 구조  
	  ![image](https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcRu5CwUjDU87fV-QHwQ5UEJelO2_1QZSopUTA&s)  
   3) Long Short Term Memory  
     - RNN의 장기 의존성 문제를 보완하여, 불필요한 과거 데이터는 삭제하고 중요 정보만 장기 기억하여 활용
	  ![image](https://miro.medium.com/v2/resize:fit:720/format:webp/1*7cMfenu76BZCzdKWCfBABA.png)  
	  장기 의존성 문제: 연산 결과를 계속 덮어 쓰는 방식으로, 앞 부분의 입력값일 수록 학습 과정에서 정보가 소실될 위험  
	  역전파 과정에서 가중치 조정이 일어날 때, 기울기가 조금씩 감소하여 0에 가까워지는 현상(기울기 소실)
   4) Generative Adversarial Network  
     - 대립하는 두 개의 신경망(데이터 생성, 데이터 구별)을 활용하여 경쟁 학습, 데이터 불균형 문제를 해결 가능  
	  ![image](https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FWlCwU%2FbtrHKdREkbz%2FbsysnUDZzbB5AgGhhG0ZTK%2Fimg.png)  
<br>

### 3. 앙상블 분석
 - 개념: 모델 성능 향상을 위해, 여러 분석 결과를 종합해 최종 결과를 도출하는 방법
 - 배깅 방식: 부트스트랩 샘플링으로 여러 표본을 추출하여 병렬 학습 후, 결과를 집계
   ![image](https://aiml.com/wp-content/uploads/2023/03/Bagging-2.png)  
   예1) 의사결정나무를 여러 개 사용하는 랜덤 포레스트  
    부트스트랩 샘플링: 복원 추출을 허용하는 샘플(표본) 추출  
    의사결정나무: 주어진 입력값들의 조합에 대한 의사결정규칙(rule)에 따라 출력값을 예측  
     ![image](https://wcs.smartdraw.com/decision-tree/img/structure-of-a-decision-tree.png?bn=15100111938)  
    랜덤 포레스트: 다수의 결정 트리로부터 부류(분류) 또는 평균 예측  
     ![image](https://miro.medium.com/v2/resize:fit:720/format:webp/1*R3oJiyaQwyLUyLZL-scDpw.png)  
 - 부스팅 방식: 모델을 점진적으로 발전시켜 나가는 방식
   예1) AdaBoost(Adaptive Boosting): 먼저 학습한 모형이 잘못 분류한 표본에 높은 가중치를 부여함
   ![image](https://media.geeksforgeeks.org/wp-content/uploads/20210707140911/Boosting.png)  


<br>
<br>
